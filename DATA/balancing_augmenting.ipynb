{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc442b2e-b124-4970-a5c4-96cb186bb1c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.12/dist-packages (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 17:22:23.976507: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-10 17:22:24.181815: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8473] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-10 17:22:24.231640: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1471] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-10 17:22:24.654276: I tensorflow/core/platform/cpu_feature_guard.cc:211] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.17.0+nv24.11)\n",
      "Requirement already satisfied: tensorflow-datasets in /home/ngx3fy/.local/lib/python3.12/site-packages (4.9.8)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (16.0.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (70.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.3.2)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: array_record>=0.5.0 in /home/ngx3fy/.local/lib/python3.12/site-packages (from tensorflow-datasets) (0.7.1)\n",
      "Requirement already satisfied: dm-tree in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets) (0.1.8)\n",
      "Requirement already satisfied: etils>=1.9.1 in /home/ngx3fy/.local/lib/python3.12/site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (1.12.2)\n",
      "Requirement already satisfied: immutabledict in /home/ngx3fy/.local/lib/python3.12/site-packages (from tensorflow-datasets) (4.2.1)\n",
      "Requirement already satisfied: promise in /home/ngx3fy/.local/lib/python3.12/site-packages (from tensorflow-datasets) (2.3)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets) (6.1.0)\n",
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets) (17.0.0)\n",
      "Requirement already satisfied: simple_parsing in /home/ngx3fy/.local/lib/python3.12/site-packages (from tensorflow-datasets) (0.1.7)\n",
      "Requirement already satisfied: tensorflow-metadata in /home/ngx3fy/.local/lib/python3.12/site-packages (from tensorflow-datasets) (1.17.0)\n",
      "Requirement already satisfied: toml in /home/ngx3fy/.local/lib/python3.12/site-packages (from tensorflow-datasets) (0.10.2)\n",
      "Requirement already satisfied: tqdm in /home/ngx3fy/.local/lib/python3.12/site-packages (from tensorflow-datasets) (4.67.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.0)\n",
      "Requirement already satisfied: einops in /home/ngx3fy/.local/lib/python3.12/site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (0.8.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (2024.10.0)\n",
      "Requirement already satisfied: importlib_resources in /home/ngx3fy/.local/lib/python3.12/site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (6.5.2)\n",
      "Requirement already satisfied: zipp in /home/ngx3fy/.local/lib/python3.12/site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (3.21.0)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /home/ngx3fy/.local/lib/python3.12/site-packages (from simple_parsing->tensorflow-datasets) (0.16)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.56.4 in /home/ngx3fy/.local/lib/python3.12/site-packages (from tensorflow-metadata->tensorflow-datasets) (1.69.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow-datasets in /home/ngx3fy/.local/lib/python3.12/site-packages (4.9.8)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets) (1.0.0)\n",
      "Requirement already satisfied: array_record>=0.5.0 in /home/ngx3fy/.local/lib/python3.12/site-packages (from tensorflow-datasets) (0.7.1)\n",
      "Requirement already satisfied: dm-tree in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets) (0.1.8)\n",
      "Requirement already satisfied: etils>=1.9.1 in /home/ngx3fy/.local/lib/python3.12/site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (1.12.2)\n",
      "Requirement already satisfied: immutabledict in /home/ngx3fy/.local/lib/python3.12/site-packages (from tensorflow-datasets) (4.2.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets) (1.26.4)\n",
      "Requirement already satisfied: promise in /home/ngx3fy/.local/lib/python3.12/site-packages (from tensorflow-datasets) (2.3)\n",
      "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets) (4.25.3)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets) (6.1.0)\n",
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets) (17.0.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets) (2.32.3)\n",
      "Requirement already satisfied: simple_parsing in /home/ngx3fy/.local/lib/python3.12/site-packages (from tensorflow-datasets) (0.1.7)\n",
      "Requirement already satisfied: tensorflow-metadata in /home/ngx3fy/.local/lib/python3.12/site-packages (from tensorflow-datasets) (1.17.0)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets) (1.1.0)\n",
      "Requirement already satisfied: toml in /home/ngx3fy/.local/lib/python3.12/site-packages (from tensorflow-datasets) (0.10.2)\n",
      "Requirement already satisfied: tqdm in /home/ngx3fy/.local/lib/python3.12/site-packages (from tensorflow-datasets) (4.67.1)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets) (1.16.0)\n",
      "Requirement already satisfied: einops in /home/ngx3fy/.local/lib/python3.12/site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (0.8.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (2024.10.0)\n",
      "Requirement already satisfied: importlib_resources in /home/ngx3fy/.local/lib/python3.12/site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (6.5.2)\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (4.12.2)\n",
      "Requirement already satisfied: zipp in /home/ngx3fy/.local/lib/python3.12/site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (3.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->tensorflow-datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->tensorflow-datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2024.8.30)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from absl-py->tensorflow-datasets) (1.16.0)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /home/ngx3fy/.local/lib/python3.12/site-packages (from simple_parsing->tensorflow-datasets) (0.16)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.56.4 in /home/ngx3fy/.local/lib/python3.12/site-packages (from tensorflow-metadata->tensorflow-datasets) (1.69.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.26.4\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "!pip install tensorflow tensorflow-datasets\n",
    "!pip install --upgrade tensorflow-datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21ebb885-5d6d-4501-9047-15b6e26755c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available class labels:\n",
      "0: Apple___Apple_scab\n",
      "1: Apple___Black_rot\n",
      "2: Apple___Cedar_apple_rust\n",
      "3: Apple___healthy\n",
      "4: Blueberry___healthy\n",
      "5: Cherry___healthy\n",
      "6: Cherry___Powdery_mildew\n",
      "7: Corn___Cercospora_leaf_spot Gray_leaf_spot\n",
      "8: Corn___Common_rust\n",
      "9: Corn___healthy\n",
      "10: Corn___Northern_Leaf_Blight\n",
      "11: Grape___Black_rot\n",
      "12: Grape___Esca_(Black_Measles)\n",
      "13: Grape___healthy\n",
      "14: Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\n",
      "15: Orange___Haunglongbing_(Citrus_greening)\n",
      "16: Peach___Bacterial_spot\n",
      "17: Peach___healthy\n",
      "18: Pepper,_bell___Bacterial_spot\n",
      "19: Pepper,_bell___healthy\n",
      "20: Potato___Early_blight\n",
      "21: Potato___healthy\n",
      "22: Potato___Late_blight\n",
      "23: Raspberry___healthy\n",
      "24: Soybean___healthy\n",
      "25: Squash___Powdery_mildew\n",
      "26: Strawberry___healthy\n",
      "27: Strawberry___Leaf_scorch\n",
      "28: Tomato___Bacterial_spot\n",
      "29: Tomato___Early_blight\n",
      "30: Tomato___healthy\n",
      "31: Tomato___Late_blight\n",
      "32: Tomato___Leaf_Mold\n",
      "33: Tomato___Septoria_leaf_spot\n",
      "34: Tomato___Spider_mites Two-spotted_spider_mite\n",
      "35: Tomato___Target_Spot\n",
      "36: Tomato___Tomato_mosaic_virus\n",
      "37: Tomato___Tomato_Yellow_Leaf_Curl_Virus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 17:22:32.664579: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9776 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:60:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Load the PlantVillage dataset\n",
    "dataset, info = tfds.load('plant_village', with_info=True, as_supervised=True)\n",
    "full_dataset = dataset['train']\n",
    "\n",
    "# Split the dataset into training and testing datasets\n",
    "\n",
    "# Load dataset metadata\n",
    "full_dataset, info = tfds.load('plant_village',split='train', with_info=True,  as_supervised=True)\n",
    "\n",
    "# Print all label names\n",
    "label_names = info.features['label'].names\n",
    "print(\"Available class labels:\")\n",
    "for i, name in enumerate(label_names):\n",
    "    print(f\"{i}: {name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3048419-4092-4476-85ba-ce10f3914515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Load the PlantVillage dataset\n",
    "dataset, info = tfds.load('plant_village', with_info=True, as_supervised=True)\n",
    "full_dataset = dataset['train']\n",
    "\n",
    "# Split the dataset into training and testing datasets\n",
    "\n",
    "# Load dataset metadata\n",
    "full_dataset, info = tfds.load('plant_village',split='train', with_info=True,  as_supervised=True)\n",
    "\n",
    "# Print all label names\n",
    "label_names = info.features['label'].names\n",
    "print(\"Available class labels:\")\n",
    "for i, name in enumerate(label_names):\n",
    "    print(f\"{i}: {name}\")\n",
    "\n",
    "# Correct tomato class names from the dataset\n",
    "tomato_classes = [\n",
    "    'Tomato___Bacterial_spot',\n",
    "    'Tomato___Early_blight',\n",
    "    'Tomato___healthy',\n",
    "    'Tomato___Late_blight',\n",
    "    'Tomato___Leaf_Mold',\n",
    "    'Tomato___Septoria_leaf_spot',\n",
    "    'Tomato___Spider_mites Two-spotted_spider_mite',\n",
    "    'Tomato___Target_Spot',\n",
    "    'Tomato___Tomato_mosaic_virus',\n",
    "    'Tomato___Tomato_Yellow_Leaf_Curl_Virus'\n",
    "]\n",
    "\n",
    "# Get indices of tomato classes\n",
    "tomato_label_indices = tf.constant([label_names.index(name) for name in tomato_classes],dtype=tf.int64)\n",
    "\n",
    "# Filter the dataset\n",
    "def filter_tomato(img, label):\n",
    "    label = tf.cast(label, tf.int64)\n",
    "    return tf.reduce_any(tf.equal(label, tomato_label_indices))\n",
    "\n",
    "tomato_dataset = full_dataset.filter(filter_tomato)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b55cdf66-bddf-4579-905a-b2d1077eec35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique class labels in the tomato dataset:\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 17:23:01.583117: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Initialize a set to store unique class labels\n",
    "unique_classes = set()\n",
    "\n",
    "# Iterate through the dataset and collect the unique class labels\n",
    "for _, label in tomato_dataset:\n",
    "    unique_classes.add(label.numpy())  # add the class label to the set\n",
    "\n",
    "# Get the class labels as a list\n",
    "unique_classes_list = sorted(list(unique_classes))\n",
    "\n",
    "# Print out the unique class labels\n",
    "print(\"Unique class labels in the tomato dataset:\")\n",
    "for label in unique_classes_list:\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94de3401-0f8d-444f-a7b5-f57503b75dc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class names present in the tomato dataset:\n",
      "Tomato___Bacterial_spot\n",
      "Tomato___Early_blight\n",
      "Tomato___healthy\n",
      "Tomato___Late_blight\n",
      "Tomato___Leaf_Mold\n",
      "Tomato___Septoria_leaf_spot\n",
      "Tomato___Spider_mites Two-spotted_spider_mite\n",
      "Tomato___Target_Spot\n",
      "Tomato___Tomato_mosaic_virus\n",
      "Tomato___Tomato_Yellow_Leaf_Curl_Virus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 17:23:30.107626: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# List of class names based on tomato diseases\n",
    "label_names = [\n",
    "    'Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Tomato___healthy',\n",
    "    'Tomato___Late_blight', 'Tomato___Leaf_Mold', 'Tomato___Septoria_leaf_spot',\n",
    "    'Tomato___Spider_mites Two-spotted_spider_mite', 'Tomato___Target_Spot',\n",
    "    'Tomato___Tomato_mosaic_virus', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus'\n",
    "]\n",
    "unique_classes_list = sorted(set([label.numpy() for _, label in tomato_dataset]))\n",
    "# Print the human-readable class names based on numeric indices\n",
    "print(\"Class names present in the tomato dataset:\")\n",
    "for index in unique_classes_list:\n",
    "    print(label_names[index - 28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e465302c-2f47-42a6-a69a-19b61c66d474",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric Label: 35\n",
      "Class Label: Tomato___Target_Spot\n",
      "Image Shape: (256, 256, 3)\n",
      "\n",
      "Numeric Label: 31\n",
      "Class Label: Tomato___Late_blight\n",
      "Image Shape: (256, 256, 3)\n",
      "\n",
      "Numeric Label: 34\n",
      "Class Label: Tomato___Spider_mites Two-spotted_spider_mite\n",
      "Image Shape: (256, 256, 3)\n",
      "\n",
      "Numeric Label: 28\n",
      "Class Label: Tomato___Bacterial_spot\n",
      "Image Shape: (256, 256, 3)\n",
      "\n",
      "Numeric Label: 31\n",
      "Class Label: Tomato___Late_blight\n",
      "Image Shape: (256, 256, 3)\n",
      "\n",
      "Numeric Label: 30\n",
      "Class Label: Tomato___healthy\n",
      "Image Shape: (256, 256, 3)\n",
      "\n",
      "Numeric Label: 34\n",
      "Class Label: Tomato___Spider_mites Two-spotted_spider_mite\n",
      "Image Shape: (256, 256, 3)\n",
      "\n",
      "Numeric Label: 36\n",
      "Class Label: Tomato___Tomato_mosaic_virus\n",
      "Image Shape: (256, 256, 3)\n",
      "\n",
      "Numeric Label: 37\n",
      "Class Label: Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
      "Image Shape: (256, 256, 3)\n",
      "\n",
      "Numeric Label: 37\n",
      "Class Label: Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
      "Image Shape: (256, 256, 3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_names = [\n",
    "    'Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Tomato___healthy',\n",
    "    'Tomato___Late_blight', 'Tomato___Leaf_Mold', 'Tomato___Septoria_leaf_spot',\n",
    "    'Tomato___Spider_mites Two-spotted_spider_mite', 'Tomato___Target_Spot',\n",
    "    'Tomato___Tomato_mosaic_virus', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus'\n",
    "]\n",
    "\n",
    "# Iterate through the dataset and print out numeric label, class name, and image shape\n",
    "for image, label in tomato_dataset.take(10):  # Take 5 samples for preview\n",
    "    numeric_label = label.numpy()  # Numeric label from dataset\n",
    "    class_name = label_names[numeric_label - 28]  # Adjust index for base value of 28\n",
    "    print(f\"Numeric Label: {numeric_label}\")\n",
    "    print(f\"Class Label: {class_name}\")\n",
    "    print(f\"Image Shape: {image.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9671900a-4d4b-465d-a312-d32e1c2b5596",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique numeric labels in the tomato dataset: [28, 29, 30, 31, 32, 33, 34, 35, 36, 37]\n",
      "\n",
      "Class names for the unique labels:\n",
      "Numeric Label: 28, Class Label: Tomato___Bacterial_spot\n",
      "Numeric Label: 29, Class Label: Tomato___Early_blight\n",
      "Numeric Label: 30, Class Label: Tomato___healthy\n",
      "Numeric Label: 31, Class Label: Tomato___Late_blight\n",
      "Numeric Label: 32, Class Label: Tomato___Leaf_Mold\n",
      "Numeric Label: 33, Class Label: Tomato___Septoria_leaf_spot\n",
      "Numeric Label: 34, Class Label: Tomato___Spider_mites Two-spotted_spider_mite\n",
      "Numeric Label: 35, Class Label: Tomato___Target_Spot\n",
      "Numeric Label: 36, Class Label: Tomato___Tomato_mosaic_virus\n",
      "Numeric Label: 37, Class Label: Tomato___Tomato_Yellow_Leaf_Curl_Virus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 17:23:58.800486: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Get all numeric labels in the dataset\n",
    "unique_labels = set()\n",
    "for image, label in tomato_dataset:\n",
    "    unique_labels.add(label.numpy())  # Add the numeric label to the set (set ensures uniqueness)\n",
    "\n",
    "# Print unique labels\n",
    "print(f\"Unique numeric labels in the tomato dataset: {sorted(unique_labels)}\")\n",
    "\n",
    "# Also, print corresponding class names\n",
    "print(\"\\nClass names for the unique labels:\")\n",
    "for label in sorted(unique_labels):\n",
    "    class_name = label_names[label - 28]  # Adjust for base index of 28\n",
    "    print(f\"Numeric Label: {label}, Class Label: {class_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bb6be53-9fe8-4141-a241-02ea6cb19038",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "\n",
    "# Count the occurrences of each label in the dataset\n",
    "class_counts = Counter()\n",
    "for _, label in tomato_dataset:\n",
    "    class_counts[label.numpy()] += 1\n",
    "\n",
    "# List of class names based on tomato diseases\n",
    "label_names = [\n",
    "    'Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Tomato___healthy',\n",
    "    'Tomato___Late_blight', 'Tomato___Leaf_Mold', 'Tomato___Septoria_leaf_spot',\n",
    "    'Tomato___Spider_mites Two-spotted_spider_mite', 'Tomato___Target_Spot',\n",
    "    'Tomato___Tomato_mosaic_virus', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus'\n",
    "]\n",
    "\n",
    "# Prepare data for plotting\n",
    "labels = [label_names[i - 28] for i in class_counts.keys()]  # Adjust for the base index of 28\n",
    "counts = [class_counts[i] for i in class_counts.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6e7e8086-0658-4288-acd4-f3c3c3df4c33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({32: 373,\n",
       "         34: 373,\n",
       "         28: 373,\n",
       "         29: 373,\n",
       "         30: 373,\n",
       "         36: 373,\n",
       "         33: 373,\n",
       "         37: 373,\n",
       "         35: 373,\n",
       "         31: 373})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "min_tomato = min(class_counts.values())\n",
    "min_tomato\n",
    "labels_before = [label_names[i - 28] for i in class_counts.keys()]\n",
    "counts_before = [class_counts[i] for i in class_counts.keys()]\n",
    "class_samples = {i: [] for i in range(28, 38)}\n",
    "for image, label in tfds.as_numpy(tomato_dataset):\n",
    "    class_samples[label].append((image, label))\n",
    "    \n",
    "tomato_balanced = []\n",
    "for label, samples in class_samples.items():\n",
    "    tomato_balanced.extend(random.sample(samples, min_tomato))\n",
    "    \n",
    "random.shuffle(tomato_balanced)\n",
    "images, labels = zip(*tomato_balanced)\n",
    "\n",
    "new_class_counts = Counter(labels)\n",
    "new_class_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e2882c3b-36d6-4608-a3e6-3f75686c4c21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def augment_image(image):\n",
    "    # Perform random augmentations\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.resize_with_crop_or_pad(image, 256, 256)\n",
    "    image = tf.image.random_crop(image, size=[200, 200, 3])\n",
    "    image = tf.image.random_contrast(image, lower=0.4, upper=2.0)\n",
    "    return image\n",
    "\n",
    "def create_augmented_dataset(images, labels, target_size=700):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "\n",
    "    # Apply augmentations to each image\n",
    "    def augment_data(image, label):\n",
    "        augmented_image = augment_image(image)\n",
    "        return augmented_image, label\n",
    "\n",
    "    # Map augmentations to the dataset\n",
    "    augmented_dataset = dataset.map(augment_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    return augmented_dataset\n",
    "\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for image, label in tfds.as_numpy(tomato_dataset):\n",
    "    images.append(image)\n",
    "    labels.append(label)\n",
    "\n",
    "# Convert lists to numpy arrays for easier handling (TensorFlow will handle the tensors)\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Create the augmented dataset\n",
    "final_dataset = create_augmented_dataset(images, labels, target_size=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "aec3f29a-2526-4b9a-b605-b93ffc9cca20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def augment_image(image):\n",
    "    \"\"\"Function to augment a single image.\"\"\"\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.resize_with_crop_or_pad(image, 256, 256)\n",
    "    image = tf.image.random_crop(image, size=[200, 200, 3])\n",
    "    image = tf.image.random_contrast(image, lower=0.4, upper=2.0)\n",
    "    return image\n",
    "\n",
    "\n",
    "def balance_classes(images, labels, target_size=700):\n",
    "    \"\"\"Ensure each class has exactly `target_size` images.\"\"\"\n",
    "    class_images = defaultdict(list)\n",
    "\n",
    "    # Group images by label\n",
    "    for img, label in zip(images, labels):\n",
    "        class_images[int(label)].append(img)\n",
    "\n",
    "    balanced_images = []\n",
    "    balanced_labels = []\n",
    "\n",
    "    for class_label, img_list in class_images.items():\n",
    "        current_count = len(img_list)\n",
    "        print(f\"Class {class_label} starts with {current_count} images\")\n",
    "\n",
    "        if current_count < target_size:\n",
    "            # Augment images to reach the target size\n",
    "            augmented_images = []\n",
    "\n",
    "            while len(augmented_images) < target_size:\n",
    "                needed = target_size - len(augmented_images)\n",
    "                to_augment = random.choices(img_list, k=needed)\n",
    "                for img in to_augment:\n",
    "                    img_tensor = tf.convert_to_tensor(img, dtype=tf.float32)\n",
    "                    img_tensor = preprocess_image(img_tensor)  # resize to [256, 256]\n",
    "                    aug_img = augment_image(img_tensor).numpy()\n",
    "                    augmented_images.append(aug_img)\n",
    "\n",
    "            balanced_images.extend(augmented_images)\n",
    "            balanced_labels.extend([class_label] * target_size)\n",
    "\n",
    "        elif current_count > target_size:\n",
    "            # Downsample\n",
    "            selected = random.sample(img_list, target_size)\n",
    "            balanced_images.extend([preprocess_image(tf.convert_to_tensor(img)).numpy() for img in selected])\n",
    "            balanced_labels.extend([class_label] * target_size)\n",
    "\n",
    "        else:\n",
    "            # Use as is\n",
    "            balanced_images.extend([preprocess_image(tf.convert_to_tensor(img)).numpy() for img in img_list])\n",
    "            balanced_labels.extend([class_label] * target_size)\n",
    "    \n",
    "\n",
    "    return balanced_images, balanced_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "594eb5d9-495a-447a-8a48-f3d8a773d100",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 28: 700 images\n",
      "Class 29: 700 images\n",
      "Class 30: 700 images\n",
      "Class 31: 700 images\n",
      "Class 32: 700 images\n",
      "Class 33: 700 images\n",
      "Class 34: 700 images\n",
      "Class 35: 700 images\n",
      "Class 36: 327 images\n",
      "Class 37: 700 images\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class_counts = Counter(balanced_labels)\n",
    "\n",
    "for class_id in sorted(class_counts):\n",
    "    print(f\"Class {class_id}: {class_counts[class_id]} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "86a74db3-6100-449e-890b-c027142f696d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Class 36 count: 373\n"
     ]
    }
   ],
   "source": [
    "original_class_36 = [img for img, label in zip(images, labels) if label == 36]\n",
    "print(f\"Original Class 36 count: {len(original_class_36)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8ab59ac7-c1be-4073-8648-14a754e5943d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "def preprocess_image(image):\n",
    "    \"\"\"Resizes image to [256, 256] for consistent shape.\"\"\"\n",
    "    return tf.image.resize(image, [256, 256])\n",
    "\n",
    "def augment_image(image):\n",
    "    \"\"\"Applies random augmentations, returns [200, 200, 3] image.\"\"\"\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.resize_with_crop_or_pad(image, 256, 256)\n",
    "    image = tf.image.random_crop(image, size=[200, 200, 3])\n",
    "    image = tf.image.random_contrast(image, lower=0.4, upper=2.0)\n",
    "    return image\n",
    "\n",
    "def balance_classes(images, labels, target_size=700):\n",
    "    class_images = defaultdict(list)\n",
    "\n",
    "    # Group by label\n",
    "    for img, label in zip(images, labels):\n",
    "        class_images[int(label)].append(img)\n",
    "\n",
    "    balanced_images = []\n",
    "    balanced_labels = []\n",
    "\n",
    "    for class_label, img_list in class_images.items():\n",
    "        print(f\"\\nProcessing class {class_label} with {len(img_list)} original images\")\n",
    "\n",
    "        current_count = len(img_list)\n",
    "        processed = []\n",
    "\n",
    "        # Preprocess all images first to avoid shape issues later\n",
    "        for img in img_list:\n",
    "            try:\n",
    "                img_tensor = tf.convert_to_tensor(img, dtype=tf.float32)\n",
    "                img_tensor = preprocess_image(img_tensor)\n",
    "                processed.append(img_tensor.numpy())\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping image due to preprocessing error: {e}\")\n",
    "\n",
    "        if len(processed) == 0:\n",
    "            print(f\"Class {class_label} has no usable images. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        if current_count < target_size:\n",
    "            # Augment until reaching target_size\n",
    "            augmented = []\n",
    "            while len(augmented) < target_size:\n",
    "                needed = target_size - len(augmented)\n",
    "                to_augment = random.choices(processed, k=needed)\n",
    "                for img in to_augment:\n",
    "                    try:\n",
    "                        img_tensor = tf.convert_to_tensor(img, dtype=tf.float32)\n",
    "                        aug_img = augment_image(img_tensor).numpy()\n",
    "                        augmented.append(aug_img)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Augmentation error in class {class_label}: {e}\")\n",
    "\n",
    "                    if len(augmented) >= target_size:\n",
    "                        break\n",
    "\n",
    "            balanced_images.extend(augmented)\n",
    "            balanced_labels.extend([class_label] * target_size)\n",
    "            print(f\"Class {class_label} balanced to {len(augmented)} images\")\n",
    "\n",
    "        elif current_count > target_size:\n",
    "            # Downsample\n",
    "            selected = random.sample(processed, target_size)\n",
    "            balanced_images.extend(selected)\n",
    "            balanced_labels.extend([class_label] * target_size)\n",
    "            print(f\"Class {class_label} downsampled to {target_size} images\")\n",
    "\n",
    "        else:\n",
    "            # Already the right size\n",
    "            balanced_images.extend(processed)\n",
    "            balanced_labels.extend([class_label] * target_size)\n",
    "            print(f\"Class {class_label} used as is with {target_size} images\")\n",
    "\n",
    "    return balanced_images, balanced_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d9ebbcc3-c1fa-4698-9d94-4a9636bd2e04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 28: 700 images\n",
      "Class 29: 700 images\n",
      "Class 30: 700 images\n",
      "Class 31: 700 images\n",
      "Class 32: 700 images\n",
      "Class 33: 700 images\n",
      "Class 34: 700 images\n",
      "Class 35: 700 images\n",
      "Class 36: 327 images\n",
      "Class 37: 700 images\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class_counts = Counter(balanced_labels)\n",
    "for class_id in sorted(class_counts):\n",
    "    print(f\"Class {class_id}: {class_counts[class_id]} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c8535a22-2b48-409f-823e-be446c0c1407",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 36 has 373 valid images\n"
     ]
    }
   ],
   "source": [
    "valid_class_36 = 0\n",
    "\n",
    "for img, label in zip(images, labels):\n",
    "    if label == 36:\n",
    "        try:\n",
    "            img_tensor = tf.convert_to_tensor(img, dtype=tf.float32)\n",
    "            _ = preprocess_image(img_tensor)  # Resize test\n",
    "            valid_class_36 += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Invalid image in class 36: {e}\")\n",
    "\n",
    "print(f\"Class 36 has {valid_class_36} valid images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "29d143fd-1bcc-4a6e-aab8-dc057a24f593",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "def preprocess_image(image):\n",
    "    \"\"\"Resizes image to [256, 256] for consistent shape.\"\"\"\n",
    "    return tf.image.resize(image, [256, 256])\n",
    "\n",
    "def augment_image(image):\n",
    "    \"\"\"Applies random augmentations, returns [200, 200, 3] image.\"\"\"\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.resize_with_crop_or_pad(image, 256, 256)\n",
    "    image = tf.image.random_crop(image, size=[200, 200, 3])\n",
    "    image = tf.image.random_contrast(image, lower=0.4, upper=2.0)\n",
    "    return image\n",
    "\n",
    "def balance_classes(images, labels, target_size=700):\n",
    "    class_images = defaultdict(list)\n",
    "\n",
    "    # Group images by label\n",
    "    for img, label in zip(images, labels):\n",
    "        class_images[int(label)].append(img)\n",
    "\n",
    "    balanced_images = []\n",
    "    balanced_labels = []\n",
    "\n",
    "    for class_label, img_list in class_images.items():\n",
    "        print(f\"\\nProcessing class {class_label} with {len(img_list)} original images\")\n",
    "\n",
    "        # Step 1: Preprocess all valid images\n",
    "        processed = []\n",
    "        for img in img_list:\n",
    "            try:\n",
    "                img_tensor = tf.convert_to_tensor(img, dtype=tf.float32)\n",
    "                img_tensor = preprocess_image(img_tensor)\n",
    "                processed.append(img_tensor.numpy())\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping bad image in class {class_label}: {e}\")\n",
    "\n",
    "        if len(processed) == 0:\n",
    "            print(f\"No valid images found for class {class_label}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Step 2: Handle class balancing\n",
    "        if len(processed) < target_size:\n",
    "            print(f\"Only {len(processed)} valid images in class {class_label}. Augmenting to {target_size}...\")\n",
    "\n",
    "            augmented = []\n",
    "\n",
    "            # ðŸ” Augment until target_size is reached\n",
    "            while len(augmented) < target_size:\n",
    "                img = random.choice(processed)\n",
    "                try:\n",
    "                    aug_img = augment_image(tf.convert_to_tensor(img)).numpy()\n",
    "                    augmented.append(aug_img)\n",
    "                except Exception as e:\n",
    "                    print(f\"Augmentation error: {e}\")\n",
    "                    continue\n",
    "\n",
    "            balanced_images.extend(augmented)\n",
    "            balanced_labels.extend([class_label] * target_size)\n",
    "            print(f\"Class {class_label} balanced to {target_size} images\")\n",
    "\n",
    "        elif len(processed) > target_size:\n",
    "            # Downsample\n",
    "            selected = random.sample(processed, target_size)\n",
    "            balanced_images.extend(selected)\n",
    "            balanced_labels.extend([class_label] * target_size)\n",
    "            print(f\"Class {class_label} downsampled to {target_size} images\")\n",
    "\n",
    "        else:\n",
    "            # Exact match\n",
    "            balanced_images.extend(processed)\n",
    "            balanced_labels.extend([class_label] * target_size)\n",
    "            print(f\"Class {class_label} already balanced\")\n",
    "\n",
    "    return balanced_images, balanced_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "01ac5df1-25f9-48a5-b4b0-18d79ce2376c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 28: 700 images\n",
      "Class 29: 700 images\n",
      "Class 30: 700 images\n",
      "Class 31: 700 images\n",
      "Class 32: 700 images\n",
      "Class 33: 700 images\n",
      "Class 34: 700 images\n",
      "Class 35: 700 images\n",
      "Class 36: 327 images\n",
      "Class 37: 700 images\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class_counts = Counter(balanced_labels)\n",
    "for class_id in sorted(class_counts):\n",
    "    print(f\"Class {class_id}: {class_counts[class_id]} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3232c9fe-f032-4737-ae43-9f7b9eb0b6f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Class 36 usable images: 373\n"
     ]
    }
   ],
   "source": [
    "valid_class_36 = []\n",
    "\n",
    "for img, label in zip(images, labels):\n",
    "    if label == 36:\n",
    "        try:\n",
    "            img_tensor = tf.convert_to_tensor(img, dtype=tf.float32)\n",
    "            resized = preprocess_image(img_tensor)\n",
    "            valid_class_36.append(resized)\n",
    "        except Exception as e:\n",
    "            print(f\"Preprocessing failed: {e}\")\n",
    "\n",
    "print(f\"Class 36 usable images: {len(valid_class_36)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "968f2b9e-96f8-47e3-864b-53a004aa9057",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "from collections import defaultdict\n",
    "\n",
    "def augment_image(image):\n",
    "    \"\"\"Function to augment a single image.\"\"\"\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.resize_with_crop_or_pad(image, 256, 256)\n",
    "    image = tf.image.random_crop(image, size=[200, 200, 3])\n",
    "    image = tf.image.random_contrast(image, lower=0.4, upper=2.0)\n",
    "    return image\n",
    "\n",
    "def preprocess_image(image):\n",
    "    \"\"\"Preprocessing function to resize image.\"\"\"\n",
    "    # Resize image to [256, 256, 3] before augmentation\n",
    "    return tf.image.resize(image, [256, 256])\n",
    "\n",
    "def balance_classes(images, labels, target_size=700):\n",
    "    \"\"\"Ensure each class has exactly `target_size` images.\"\"\"\n",
    "    class_images = defaultdict(list)\n",
    "\n",
    "    # Group images by label\n",
    "    for img, label in zip(images, labels):\n",
    "        class_images[int(label)].append(img)\n",
    "\n",
    "    balanced_images = []\n",
    "    balanced_labels = []\n",
    "\n",
    "    for class_label, img_list in class_images.items():\n",
    "        current_count = len(img_list)\n",
    "        print(f\"Class {class_label} starts with {current_count} images\")\n",
    "\n",
    "        if current_count < target_size:\n",
    "            # Augment images to reach the target size\n",
    "            augmented_images = []\n",
    "\n",
    "            while len(augmented_images) < target_size:\n",
    "                needed = target_size - len(augmented_images)\n",
    "                to_augment = random.choices(img_list, k=needed)\n",
    "\n",
    "                for img in to_augment:\n",
    "                    img_tensor = tf.convert_to_tensor(img, dtype=tf.float32)\n",
    "                    img_tensor = preprocess_image(img_tensor)  # resize to [256, 256]\n",
    "                    try:\n",
    "                        aug_img = augment_image(img_tensor).numpy()\n",
    "                        augmented_images.append(aug_img)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Augmentation error: {e}\")\n",
    "                        continue\n",
    "\n",
    "            balanced_images.extend(augmented_images)\n",
    "            balanced_labels.extend([class_label] * target_size)\n",
    "\n",
    "        elif current_count > target_size:\n",
    "            # Downsample to target size\n",
    "            selected = random.sample(img_list, target_size)\n",
    "            balanced_images.extend([preprocess_image(tf.convert_to_tensor(img)).numpy() for img in selected])\n",
    "            balanced_labels.extend([class_label] * target_size)\n",
    "\n",
    "        else:\n",
    "            # Use as is\n",
    "            balanced_images.extend([preprocess_image(tf.convert_to_tensor(img)).numpy() for img in img_list])\n",
    "            balanced_labels.extend([class_label] * target_size)\n",
    "    \n",
    "    return balanced_images, balanced_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "433ebbb3-579c-45f0-a67a-b9588e256d4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 32 starts with 373 images\n",
      "Class 34 starts with 373 images\n",
      "Class 28 starts with 373 images\n",
      "Class 29 starts with 373 images\n",
      "Class 30 starts with 373 images\n",
      "Class 36 starts with 373 images\n",
      "Class 33 starts with 373 images\n",
      "Class 37 starts with 373 images\n",
      "Class 35 starts with 373 images\n",
      "Class 31 starts with 373 images\n",
      "Class 28: 700 images\n",
      "Class 29: 700 images\n",
      "Class 30: 700 images\n",
      "Class 31: 700 images\n",
      "Class 32: 700 images\n",
      "Class 33: 700 images\n",
      "Class 34: 700 images\n",
      "Class 35: 700 images\n",
      "Class 36: 700 images\n",
      "Class 37: 700 images\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# After calling balance_classes function\n",
    "balanced_images, balanced_labels = balance_classes(images, labels, target_size=700)\n",
    "\n",
    "# Use Counter to count the occurrences of each class in balanced_labels\n",
    "class_counts = Counter(balanced_labels)\n",
    "\n",
    "# Print class count\n",
    "for class_id, count in sorted(class_counts.items()):\n",
    "    print(f\"Class {class_id}: {count} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "96b64a90-3710-4976-99f5-a6e75f588880",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# Assuming you already have balanced_labels from the balance_classes function\n",
    "# balanced_labels contains the class labels after balancing\n",
    "\n",
    "# Use Counter to count the occurrences of each class in balanced_labels\n",
    "class_counts = Counter(balanced_labels)\n",
    "\n",
    "# Prepare data for plotting\n",
    "classes = list(class_counts.keys())  # List of class IDs\n",
    "counts = list(class_counts.values())  # Corresponding counts of each class\n",
    "\n",
    "# Create a bar graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(classes, counts, color='forestgreen')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Class ID')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Class Distribution After Balancing')\n",
    "\n",
    "# Show the plot\n",
    "plt.xticks(classes)  # Set x-axis labels to class IDs\n",
    "plt.tight_layout()  # Adjust layout to prevent clipping of labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e575372-93df-4983-95c0-7a4e57ce103d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow 2.17.0",
   "language": "python",
   "name": "tensorflow-2.17.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
